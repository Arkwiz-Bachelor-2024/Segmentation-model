We are running from this directory: /cluster/work/petteed/seg_model/Segmentation-model
---------------------------------------------------------
The name of the job is: U_NET_50e_64b+DA
The job ID is 19053321
---------------------------------------------------------
The job was run on these nodes: idun-06-16
Number of nodes: 1
---------------------------------------------------------
Assert Enviroment modules are loaded...
---------------------------------------------------------
Assert python modules are loaded....
Requirement already satisfied: scikit-learn in /cluster/home/petteed/.local/lib/python3.10/site-packages (1.4.1.post1)
Requirement already satisfied: joblib>=1.2.0 in /cluster/home/petteed/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)
Requirement already satisfied: scipy>=1.6.0 in /cluster/apps/eb/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from scikit-learn) (1.8.1)
Requirement already satisfied: numpy<2.0,>=1.19.5 in /cluster/apps/eb/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from scikit-learn) (1.22.3)
Requirement already satisfied: threadpoolctl>=2.0.0 in /cluster/apps/eb/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from scikit-learn) (3.1.0)
Requirement already satisfied: matplotlib in /cluster/home/petteed/.local/lib/python3.10/site-packages (3.8.3)
Requirement already satisfied: contourpy>=1.0.1 in /cluster/home/petteed/.local/lib/python3.10/site-packages (from matplotlib) (1.2.0)
Requirement already satisfied: kiwisolver>=1.3.1 in /cluster/home/petteed/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)
Requirement already satisfied: python-dateutil>=2.7 in /cluster/apps/eb/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib) (2.8.2)
Requirement already satisfied: pyparsing>=2.3.1 in /cluster/apps/eb/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib) (3.0.8)
Requirement already satisfied: fonttools>=4.22.0 in /cluster/home/petteed/.local/lib/python3.10/site-packages (from matplotlib) (4.50.0)
Requirement already satisfied: pillow>=8 in /cluster/home/petteed/.local/lib/python3.10/site-packages (from matplotlib) (10.2.0)
Requirement already satisfied: cycler>=0.10 in /cluster/home/petteed/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)
Requirement already satisfied: numpy<2,>=1.21 in /cluster/apps/eb/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from matplotlib) (1.22.3)
Requirement already satisfied: packaging>=20.0 in /cluster/apps/eb/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib) (23.2)
Requirement already satisfied: six>=1.5 in /cluster/apps/eb/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)
Requirement already satisfied: cython in /cluster/apps/eb/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (0.29.28)
Collecting git+https://github.com/lucasb-eyer/pydensecrf.git
  Cloning https://github.com/lucasb-eyer/pydensecrf.git to /tmp/pip-req-build-q952obo4
  Resolved https://github.com/lucasb-eyer/pydensecrf.git to commit 2723c7fa4f2ead16ae1ce3d8afe977724bb8f87f
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
---------------------------------------------------------
GPU specifications:
Thu Apr  4 05:02:15 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:03:00.0 Off |                    0 |
| N/A   31C    P0              33W / 250W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-PCIE-40GB          On  | 00000000:82:00.0 Off |                    0 |
| N/A   32C    P0              31W / 250W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
---------------------------------------------------------
Training model:
---------------------------------------------------------
---------------------------------------------------------------------------------------------------
Enviroment:
TensorFlow version: 2.11.0
GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]
---------------------------------------------------------------------------------------------------
Details:
---------------------------------------------------------------------------------------------------
Classes:  5
Batch size: 64
Epochs 50
Training samples : 117
---------------------------------------------------------------------------------------------------
Data shape
Image shape: (64, 512, 512, 3)
Mask shape: (64, 512, 512, 1)
Training dataset:  <BatchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 512, 512, 1), dtype=tf.uint8, name=None))>
---------------------------------------------------------------------------------------------------
Epoch 1/50

Epoch 1: val_loss improved from inf to 2.60171, saving model to ./models/U_NET_50e_64b+DA
117/117 - 703s - loss: 2.1279 - val_loss: 2.6017 - 703s/epoch - 6s/step
Epoch 2/50

Epoch 2: val_loss did not improve from 2.60171
117/117 - 444s - loss: 1.2219 - val_loss: 3.4145 - 444s/epoch - 4s/step
Epoch 3/50

Epoch 3: val_loss did not improve from 2.60171
117/117 - 467s - loss: 1.0810 - val_loss: 3.5370 - 467s/epoch - 4s/step
Epoch 4/50

Epoch 4: val_loss did not improve from 2.60171
117/117 - 444s - loss: 1.0018 - val_loss: 3.2261 - 444s/epoch - 4s/step
Epoch 5/50

Epoch 5: val_loss improved from 2.60171 to 2.04053, saving model to ./models/U_NET_50e_64b+DA
117/117 - 487s - loss: 0.9550 - val_loss: 2.0405 - 487s/epoch - 4s/step
Epoch 6/50

Epoch 6: val_loss improved from 2.04053 to 0.95906, saving model to ./models/U_NET_50e_64b+DA
117/117 - 479s - loss: 0.9255 - val_loss: 0.9591 - 479s/epoch - 4s/step
Epoch 7/50

Epoch 7: val_loss improved from 0.95906 to 0.81263, saving model to ./models/U_NET_50e_64b+DA
117/117 - 521s - loss: 0.8876 - val_loss: 0.8126 - 521s/epoch - 4s/step
Epoch 8/50

Epoch 8: val_loss improved from 0.81263 to 0.77238, saving model to ./models/U_NET_50e_64b+DA
117/117 - 573s - loss: 0.8654 - val_loss: 0.7724 - 573s/epoch - 5s/step
Epoch 9/50

Epoch 9: val_loss did not improve from 0.77238
117/117 - 456s - loss: 0.8484 - val_loss: 0.7929 - 456s/epoch - 4s/step
Epoch 10/50

Epoch 10: val_loss did not improve from 0.77238
117/117 - 442s - loss: 0.8393 - val_loss: 0.7731 - 442s/epoch - 4s/step
Epoch 11/50

Epoch 11: val_loss improved from 0.77238 to 0.73989, saving model to ./models/U_NET_50e_64b+DA
117/117 - 461s - loss: 0.8224 - val_loss: 0.7399 - 461s/epoch - 4s/step
Epoch 12/50

Epoch 12: val_loss improved from 0.73989 to 0.69441, saving model to ./models/U_NET_50e_64b+DA
117/117 - 462s - loss: 0.8134 - val_loss: 0.6944 - 462s/epoch - 4s/step
Epoch 13/50

Epoch 13: val_loss improved from 0.69441 to 0.68874, saving model to ./models/U_NET_50e_64b+DA
117/117 - 476s - loss: 0.7986 - val_loss: 0.6887 - 476s/epoch - 4s/step
Epoch 14/50

Epoch 14: val_loss improved from 0.68874 to 0.67643, saving model to ./models/U_NET_50e_64b+DA
117/117 - 461s - loss: 0.7862 - val_loss: 0.6764 - 461s/epoch - 4s/step
Epoch 15/50

Epoch 15: val_loss improved from 0.67643 to 0.67461, saving model to ./models/U_NET_50e_64b+DA
117/117 - 463s - loss: 0.7800 - val_loss: 0.6746 - 463s/epoch - 4s/step
Epoch 16/50

Epoch 16: val_loss improved from 0.67461 to 0.66234, saving model to ./models/U_NET_50e_64b+DA
117/117 - 469s - loss: 0.7700 - val_loss: 0.6623 - 469s/epoch - 4s/step
Epoch 17/50

Epoch 17: val_loss did not improve from 0.66234
117/117 - 443s - loss: 0.7650 - val_loss: 0.6631 - 443s/epoch - 4s/step
Epoch 18/50

Epoch 18: val_loss did not improve from 0.66234
117/117 - 448s - loss: 0.7442 - val_loss: 0.6662 - 448s/epoch - 4s/step
Epoch 19/50

Epoch 19: val_loss did not improve from 0.66234
117/117 - 443s - loss: 0.7357 - val_loss: 0.6653 - 443s/epoch - 4s/step
Epoch 20/50

Epoch 20: val_loss improved from 0.66234 to 0.64293, saving model to ./models/U_NET_50e_64b+DA
117/117 - 461s - loss: 0.7318 - val_loss: 0.6429 - 461s/epoch - 4s/step
Epoch 21/50

Epoch 21: val_loss did not improve from 0.64293
117/117 - 457s - loss: 0.7197 - val_loss: 0.6472 - 457s/epoch - 4s/step
Epoch 22/50

Epoch 22: val_loss did not improve from 0.64293
117/117 - 442s - loss: 0.7035 - val_loss: 0.6479 - 442s/epoch - 4s/step
Epoch 23/50

Epoch 23: val_loss did not improve from 0.64293
117/117 - 442s - loss: 0.6923 - val_loss: 0.6480 - 442s/epoch - 4s/step
Epoch 24/50

Epoch 24: val_loss did not improve from 0.64293
117/117 - 513s - loss: 0.6888 - val_loss: 0.6444 - 513s/epoch - 4s/step
Epoch 25/50

Epoch 25: val_loss improved from 0.64293 to 0.64263, saving model to ./models/U_NET_50e_64b+DA
117/117 - 504s - loss: 0.6767 - val_loss: 0.6426 - 504s/epoch - 4s/step
Epoch 26/50

Epoch 26: val_loss improved from 0.64263 to 0.61778, saving model to ./models/U_NET_50e_64b+DA
117/117 - 461s - loss: 0.6712 - val_loss: 0.6178 - 461s/epoch - 4s/step
Epoch 27/50

Epoch 27: val_loss did not improve from 0.61778
117/117 - 451s - loss: 0.6514 - val_loss: 0.6466 - 451s/epoch - 4s/step
Epoch 28/50

Epoch 28: val_loss did not improve from 0.61778
117/117 - 443s - loss: 0.6457 - val_loss: 0.6673 - 443s/epoch - 4s/step
Epoch 29/50

Epoch 29: val_loss did not improve from 0.61778
117/117 - 449s - loss: 0.6334 - val_loss: 0.6285 - 449s/epoch - 4s/step
Epoch 30/50

Epoch 30: val_loss did not improve from 0.61778
117/117 - 458s - loss: 0.6214 - val_loss: 0.6231 - 458s/epoch - 4s/step
Epoch 31/50

Epoch 31: val_loss did not improve from 0.61778
117/117 - 450s - loss: 0.6002 - val_loss: 0.6602 - 450s/epoch - 4s/step
Epoch 32/50

Epoch 32: val_loss did not improve from 0.61778
117/117 - 444s - loss: 0.5833 - val_loss: 0.6389 - 444s/epoch - 4s/step
Epoch 33/50

Epoch 33: val_loss did not improve from 0.61778
117/117 - 443s - loss: 0.5841 - val_loss: 0.6462 - 443s/epoch - 4s/step
Epoch 34/50

Epoch 34: val_loss did not improve from 0.61778
117/117 - 442s - loss: 0.5713 - val_loss: 0.6747 - 442s/epoch - 4s/step
Epoch 34: early stopping
Training completed
---------------------------------------------------------
---------------------------------------------------------
Script completed
